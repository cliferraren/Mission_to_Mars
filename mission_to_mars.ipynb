{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Scraping\n",
    "\n",
    "Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "* Create a Jupyter Notebook file called `mission_to_mars.ipynb` and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the BeautifulSoup class creator from the package bs4.\n",
    "#Import Broser from splintre package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to init browser to Chrome\n",
    "\n",
    "def init_browser():\n",
    "    executable_path = {\"executable_path\": \"/Users/rck/chrome_driver/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News\n",
    "\n",
    "* Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragragh Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape the Latest News Article from NASA\n",
    "#get only the first(latest) article\n",
    "#1st scrape method declared\n",
    "\n",
    "def get_news():\n",
    "    url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "    \n",
    "    #try catch block to catch if error is encountered, pass will return the title and paragraph element of the article\n",
    "    try:\n",
    "        browser.visit(url)\n",
    "        html_string = browser.html\n",
    "        soup = bs(html_string, 'html.parser')\n",
    "\n",
    "        div = soup.find('div', attrs={'class': 'list_text'})\n",
    "        title=div.findNext('div', {'class': 'content_title'}).text            \n",
    "        description=div.findNext('div', {'class': 'article_teaser_body'}).text\n",
    "    except:\n",
    "        pass\n",
    "    return {\"news_title\":title,\"news_p\":description}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "\n",
    "* Visit the url for JPL's Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "\n",
    "* Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "\n",
    "* Make sure to find the image url to the full size `.jpg` image.\n",
    "\n",
    "* Make sure to save a complete url string for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape the image URL from JPL page\n",
    "def get_featured_image():\n",
    "    url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "    \n",
    "    #try catch block to catch if error is encountered, pass will return image URL\n",
    "    try:\n",
    "        browser.visit(url)\n",
    "        button = browser.find_by_id(\"full_image\")\n",
    "        button.click()\n",
    "        time.sleep(2) # will pause the execution of the loop for a specified amount of seconds\n",
    "\n",
    "        html_string = browser.html\n",
    "        \n",
    "        #The 'html.parser' argument indicates that we want to do the parsing using Python’s built-in HTML parser.\n",
    "        soup = bs(html_string, 'html.parser')\n",
    "        anchor = soup.find('a','ready')\n",
    "        if anchor.img:\n",
    "            image_url = anchor.img['src']\n",
    "        featured_image_url = \"https://www.jpl.nasa.gov\" + image_url      \n",
    "    except:\n",
    "        pass\n",
    "    return featured_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather\n",
    "\n",
    "* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get latest weather update from Twitter\n",
    "def get_latest_weather():\n",
    "    url = 'https://twitter.com/marswxreport?lang=en'\n",
    "    \n",
    "    #try catch block to catch if error is encountered, pass will return latest weather update\n",
    "    try:\n",
    "        browser.visit(url)\n",
    "        html_string = browser.html\n",
    "        soup = bs(html_string, 'lxml')\n",
    "        \n",
    "        latest_weather = soup.find('div','js-tweet-text-container').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    return latest_weather "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts\n",
    "\n",
    "* Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get Mars Facts information from Mars Facts webpage\n",
    "def get_facts(): \n",
    "    url = 'https://space-facts.com/mars/'\n",
    "    \n",
    "    #try catch block to catch if error is encountered, pass will return mars facts if passed\n",
    "    try:\n",
    "        browser.visit(url)\n",
    "        html_string = browser.html\n",
    "        soup = bs(html_string, 'lxml')\n",
    "\n",
    "        keys =[]\n",
    "        values=[]\n",
    "        table = soup.find('table','tablepress tablepress-id-mars')\n",
    "        for row in table.find_all('tr'):\n",
    "            columns = row.find_all('td')\n",
    "            keys.append(columns[0].text)\n",
    "            values.append(columns[1].text)\n",
    "        facts = dict(zip(keys, values)) #facts in a dictionary as key-value pair\n",
    "    except:\n",
    "        pass\n",
    "    return facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemisperes\n",
    "\n",
    "* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "\n",
    "* You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "\n",
    "* Save both the image url string for the full resolution hemipshere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "\n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to to obtain high resolution images for each of Mar's hemispheres\n",
    "def get_hemispheres():\n",
    "    hemisphere_image_urls = []\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars' \n",
    "    \n",
    "    #try catch block to catch if error is encountered, pass will return Mar's hemispheres images\n",
    "    try:\n",
    "        browser.visit(url)     \n",
    "        html_string = browser.html\n",
    "        soup = bs(html_string, 'lxml')\n",
    "\n",
    "        for header in soup.find_all(\"h3\"):\n",
    "            title = header.text\n",
    "            uri = header.find_previous(\"a\")\n",
    "            image_url = 'https://astrogeology.usgs.gov'+ uri['href'] \n",
    "            browser.visit(image_url)\n",
    "\n",
    "            sub_html_string = browser.html\n",
    "            sub_soup = bs(sub_html_string, 'lxml')\n",
    "            image_url='https://astrogeology.usgs.gov' + str(sub_soup.find('img','wide-image')['src'])\n",
    "            hemisphere_image_urls.append({\"title\": title, \"img_url\": image_url})\n",
    "            browser.back()\n",
    "    except:\n",
    "        pass\n",
    "    return hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function scrape to call the functions created to scrape various needed information from various website and consolidate it \n",
    "#it to output object which is initialize as empty object.\n",
    "def scrape():\n",
    "    output = {}\n",
    "    \n",
    "    #call news scrape function - 1st scrape method\n",
    "    news = get_news()\n",
    "    \n",
    "    #call image URL scrape function - 2nd scrape method\n",
    "    featured_image_url= get_featured_image()\n",
    "    \n",
    "    #get latest weather update from Twitter - 3rd scrape method\n",
    "    latest_weather=get_latest_weather()\n",
    "    \n",
    "    #get Mars Facts information from Mars Facts webpage -4th scrape method\n",
    "    facts =get_facts()\n",
    "    \n",
    "    #Obtain high resolution images for each of Mar's hemispheres -5th declared scrape method\n",
    "    hemisphere_image_urls =get_hemispheres() \n",
    "    \n",
    "    #save all scrape information into output as key-value pair into a dictionary\n",
    "    output ={ \"news\":news,\"featured_image_url\":featured_image_url,\"weather\":latest_weather,\"facts\":facts, \"hemisphere_image_urls\":hemisphere_image_urls\n",
    "    }\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to initialize Chrome Browser using Splinter\n",
    "browser = init_browser()\n",
    "\n",
    "#call scrape function to call the other scraping methods and return the consolidated information into output object\n",
    "output = scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"news\": {\n",
      "        \"news_title\": \"Mars Helicopter to Fly on NASA\\u2019s Next Red Planet Rover Mission\",\n",
      "        \"news_p\": \"NASA is adding a Mars helicopter to the agency\\u2019s next mission to the Red Planet, Mars 2020.\"\n",
      "    },\n",
      "    \"featured_image_url\": \"https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA17440_ip.jpg\",\n",
      "    \"weather\": \"Sol 2047 (May 10, 2018), Sunny, high 3C/37F, low -71C/-95F, pressure at 7.33 hPa, daylight 05:22-17:20\",\n",
      "    \"facts\": {\n",
      "        \"Equatorial Diameter:\": \"6,792 km\\n\",\n",
      "        \"Polar Diameter:\": \"6,752 km\\n\",\n",
      "        \"Mass:\": \"6.42 x 10^23 kg (10.7% Earth)\",\n",
      "        \"Moons:\": \"2 (Phobos & Deimos)\",\n",
      "        \"Orbit Distance:\": \"227,943,824 km (1.52 AU)\",\n",
      "        \"Orbit Period:\": \"687 days (1.9 years)\\n\",\n",
      "        \"Surface Temperature: \": \"-153 to 20 \\u00b0C\",\n",
      "        \"First Record:\": \"2nd millennium BC\",\n",
      "        \"Recorded By:\": \"Egyptian astronomers\"\n",
      "    },\n",
      "    \"hemisphere_image_urls\": [\n",
      "        {\n",
      "            \"title\": \"Cerberus Hemisphere Enhanced\",\n",
      "            \"img_url\": \"https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Schiaparelli Hemisphere Enhanced\",\n",
      "            \"img_url\": \"https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Syrtis Major Hemisphere Enhanced\",\n",
      "            \"img_url\": \"https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Valles Marineris Hemisphere Enhanced\",\n",
      "            \"img_url\": \"https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#import json dependencies since output object (return value was a list of k-v pair/JSON format/dictionary)\n",
    "#print the output object to view the parse information from 5 parsing methods created earlier\n",
    "\n",
    "import json\n",
    "print(json.dumps(output,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - MongoDB and Flask Application\n",
    "\n",
    "Use MongoDB with Flask templating to create a new HTML page that displays all of the information that was scraped from the URLs above.\n",
    "\n",
    "* Start by converting your Jupyter notebook into a Python script called `scrape_mars.py` with a function called `scrape` that will execute all of your scraping code from above and return one Python dictionary containing all of the scraped data.\n",
    "\n",
    "* Next, create a route called `/scrape` that will import your `scrape_mars.py` script and call your `scrape` function.\n",
    "\n",
    "  * Store the return value in Mongo as a Python dictionary.\n",
    "\n",
    "* Create a root route `/` that will query your Mongo database and pass the mars data into an HTML template to display the data.\n",
    "\n",
    "* Create a template HTML file called `index.html` that will take the mars data dictionary and display all of the data in the appropriate HTML elements. Use the following as a guide for what the final product should look like, but feel free to create your own design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies needed to store the parse information into a Mongo Database\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the mongodb server and use mission_to_mars database\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.mission_to_mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5af6774b3c64973a4c8a03eb'),\n",
       " 'facts': {'Equatorial Diameter:': '6,792 km\\n',\n",
       "  'First Record:': '2nd millennium BC',\n",
       "  'Mass:': '6.42 x 10^23 kg (10.7% Earth)',\n",
       "  'Moons:': '2 (Phobos & Deimos)',\n",
       "  'Orbit Distance:': '227,943,824 km (1.52 AU)',\n",
       "  'Orbit Period:': '687 days (1.9 years)\\n',\n",
       "  'Polar Diameter:': '6,752 km\\n',\n",
       "  'Recorded By:': 'Egyptian astronomers',\n",
       "  'Surface Temperature: ': '-153 to 20 °C'},\n",
       " 'featured_image_url': 'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA17009_ip.jpg',\n",
       " 'hemisphere_image_urls': [{'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg',\n",
       "   'title': 'Cerberus Hemisphere Enhanced'},\n",
       "  {'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg',\n",
       "   'title': 'Schiaparelli Hemisphere Enhanced'},\n",
       "  {'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg',\n",
       "   'title': 'Syrtis Major Hemisphere Enhanced'},\n",
       "  {'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg',\n",
       "   'title': 'Valles Marineris Hemisphere Enhanced'}],\n",
       " 'news': {'news_p': 'NASA is adding a Mars helicopter to the agency’s next mission to the Red Planet, Mars 2020.',\n",
       "  'news_title': 'Mars Helicopter to Fly on NASA’s Next Red Planet Rover Mission'},\n",
       " 'weather': 'Sol 2047 (May 10, 2018), Sunny, high 3C/37F, low -71C/-95F, pressure at 7.33 hPa, daylight 05:22-17:20'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use mars_info collection on mission_to_marsDB\n",
    "#query information from the DB and mars_info collection\n",
    "#display the parse information that is save to the mongo db\n",
    "new_info = db.mars_info.find_one()\n",
    "new_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_title': 'Mars Helicopter to Fly on NASA’s Next Red Planet Rover Mission', 'news_p': 'NASA is adding a Mars helicopter to the agency’s next mission to the Red Planet, Mars 2020.'}\n",
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA17009_ip.jpg\n",
      "Sol 2047 (May 10, 2018), Sunny, high 3C/37F, low -71C/-95F, pressure at 7.33 hPa, daylight 05:22-17:20\n",
      "{'Equatorial Diameter:': '6,792 km\\n', 'Polar Diameter:': '6,752 km\\n', 'Mass:': '6.42 x 10^23 kg (10.7% Earth)', 'Moons:': '2 (Phobos & Deimos)', 'Orbit Distance:': '227,943,824 km (1.52 AU)', 'Orbit Period:': '687 days (1.9 years)\\n', 'Surface Temperature: ': '-153 to 20 °C', 'First Record:': '2nd millennium BC', 'Recorded By:': 'Egyptian astronomers'}\n",
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]\n"
     ]
    }
   ],
   "source": [
    "#Display the consolidated information queried from the mongo DB\n",
    "for k, v in new_info.items(): \n",
    "    if k == \"news\":\n",
    "        news = v\n",
    "    elif k == \"featured_image_url\":\n",
    "        featured_image_url = v\n",
    "    elif k == \"weather\":\n",
    "        weather = v\n",
    "    elif k == \"facts\":\n",
    "        facts = v\n",
    "    elif k == \"hemisphere_image_urls\":\n",
    "        hemisphere_image_urls = v\n",
    "print(news)\n",
    "print(featured_image_url)\n",
    "print(weather)\n",
    "print(facts)\n",
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
